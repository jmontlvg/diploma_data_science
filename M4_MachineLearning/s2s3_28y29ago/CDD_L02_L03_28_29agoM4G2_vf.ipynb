{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22 AGO 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from statsmodels.api import OLS\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as la\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas de Regresión como un Problema de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recordar, modelo de regresión lineal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = X\\beta + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  \\begin{bmatrix}\n",
    "        y_1 \\\\\n",
    "        y_2 \\\\\n",
    "        \\vdots \\\\\n",
    "        y_n \\\\\n",
    "        \\end{bmatrix}\n",
    "        = \\begin{bmatrix}\n",
    "                1 & x_{1,1} & x_{1,2} & \\ldots & x_{1,p}\\\\\n",
    "                1 & x_{2,1} & x_{2,2} & \\ldots & x_{2,p}\\\\\n",
    "                \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "                1 & x_{n,1} & x_{n,2} & \\ldots & x_{n,p}\\\\\n",
    "          \\end{bmatrix}  \\begin{bmatrix} \n",
    "                \\beta_{0}\\\\ \n",
    "                \\beta_{1}\\\\\n",
    "                \\ldots \\\\\n",
    "                \\beta_{p}\\\\\n",
    "             \\end{bmatrix} + \\begin{bmatrix} \n",
    "                \\epsilon_{1}\\\\ \n",
    "                \\epsilon_{2}\\\\\n",
    "                \\ldots \\\\\n",
    "                \\epsilon_{n}\\\\\n",
    "             \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde el criterio (de **mínimos cuadrados**) es minimizar la SUMA DEL CUADRADO DE LOS ERRORES:\n",
    "\n",
    "$$\n",
    "SSE = \\epsilon^{\\prime}\\epsilon = (y - X\\beta)^{\\prime}(y - X\\beta) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución al problema anterior es el estimador de Mínimos Cuadrados:\n",
    "\n",
    "$$\n",
    "\\hat\\beta = (X^{\\prime}X)^{-1}X^{\\prime}y\n",
    "$$\n",
    "\n",
    "y los valores predichos o estimados son:\n",
    "\n",
    "$$\n",
    "\\hat y =  X\\hat\\beta\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visto como un modelo de machine learning, tenemos que entrenarlo en un conjunto de datos y probar su desempeño en otro, y lo que\n",
    "# nos interesa es la PREDICCIÓN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0  A1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1  A2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2  A3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3  A4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4  A5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('boston_house_prices.csv')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significado variables\n",
    "1. CRIM: per capita crime rate by town\n",
    "2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS: proportion of non-retail business acres per town\n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. NOX: nitric oxides concentration (parts per 10 million)\n",
    "6. RM: average number of rooms per dwelling\n",
    "7. AGE: proportion of owner-occupied units built prior to 1940\n",
    "8. DIS: weighted distances to ﬁve Boston employment centers\n",
    "9. RAD: index of accessibility to radial highways\n",
    "10. TAX: full-value property-tax rate per 10,000\n",
    "11. PTRATIO: pupil-teacher ratio by town \n",
    "12. B: 1000(Bk−0.63)2 where Bk is the proportion of blacks by town \n",
    "13. LSTAT: % lower status of the population\n",
    "14. MEDV: Median value of owner-occupied homes in '$1000s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = boston\n",
    "predictors = df.loc[:,'CRIM':'LSTAT']\n",
    "response = df['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared (uncentered):</th>      <td>   0.959</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.957</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   654.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 02 Sep 2024</td> <th>  Prob (F-statistic):</th>          <td>3.71e-244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:43:34</td>     <th>  Log-Likelihood:    </th>          <td> -1141.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   379</td>      <th>  AIC:               </th>          <td>   2310.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   366</td>      <th>  BIC:               </th>          <td>   2361.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.1312</td> <td>    0.041</td> <td>   -3.236</td> <td> 0.001</td> <td>   -0.211</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0448</td> <td>    0.018</td> <td>    2.543</td> <td> 0.011</td> <td>    0.010</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>    0.0077</td> <td>    0.078</td> <td>    0.098</td> <td> 0.922</td> <td>   -0.146</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    2.5157</td> <td>    1.045</td> <td>    2.407</td> <td> 0.017</td> <td>    0.460</td> <td>    4.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>   -3.3773</td> <td>    4.116</td> <td>   -0.821</td> <td> 0.412</td> <td>  -11.470</td> <td>    4.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    5.8394</td> <td>    0.374</td> <td>   15.619</td> <td> 0.000</td> <td>    5.104</td> <td>    6.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>   -0.0104</td> <td>    0.016</td> <td>   -0.661</td> <td> 0.509</td> <td>   -0.041</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -0.9479</td> <td>    0.228</td> <td>   -4.150</td> <td> 0.000</td> <td>   -1.397</td> <td>   -0.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.2115</td> <td>    0.080</td> <td>    2.654</td> <td> 0.008</td> <td>    0.055</td> <td>    0.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0119</td> <td>    0.005</td> <td>   -2.526</td> <td> 0.012</td> <td>   -0.021</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.3033</td> <td>    0.135</td> <td>   -2.243</td> <td> 0.026</td> <td>   -0.569</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0146</td> <td>    0.003</td> <td>    4.538</td> <td> 0.000</td> <td>    0.008</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.4181</td> <td>    0.060</td> <td>   -6.988</td> <td> 0.000</td> <td>   -0.536</td> <td>   -0.300</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>187.113</td> <th>  Durbin-Watson:     </th> <td>   1.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1593.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.898</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>12.300</td>  <th>  Cond. No.          </th> <td>8.96e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 8.96e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       MEDV       & \\textbf{  R-squared (uncentered):}      &     0.959   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.957   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     654.2   \\\\\n",
       "\\textbf{Date:}             & Mon, 02 Sep 2024 & \\textbf{  Prob (F-statistic):}          & 3.71e-244   \\\\\n",
       "\\textbf{Time:}             &     19:43:34     & \\textbf{  Log-Likelihood:    }          &   -1141.9   \\\\\n",
       "\\textbf{No. Observations:} &         379      & \\textbf{  AIC:               }          &     2310.   \\\\\n",
       "\\textbf{Df Residuals:}     &         366      & \\textbf{  BIC:               }          &     2361.   \\\\\n",
       "\\textbf{Df Model:}         &          13      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                 & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{CRIM}    &      -0.1312  &        0.041     &    -3.236  &         0.001        &       -0.211    &       -0.051     \\\\\n",
       "\\textbf{ZN}      &       0.0448  &        0.018     &     2.543  &         0.011        &        0.010    &        0.079     \\\\\n",
       "\\textbf{INDUS}   &       0.0077  &        0.078     &     0.098  &         0.922        &       -0.146    &        0.161     \\\\\n",
       "\\textbf{CHAS}    &       2.5157  &        1.045     &     2.407  &         0.017        &        0.460    &        4.571     \\\\\n",
       "\\textbf{NOX}     &      -3.3773  &        4.116     &    -0.821  &         0.412        &      -11.470    &        4.716     \\\\\n",
       "\\textbf{RM}      &       5.8394  &        0.374     &    15.619  &         0.000        &        5.104    &        6.575     \\\\\n",
       "\\textbf{AGE}     &      -0.0104  &        0.016     &    -0.661  &         0.509        &       -0.041    &        0.020     \\\\\n",
       "\\textbf{DIS}     &      -0.9479  &        0.228     &    -4.150  &         0.000        &       -1.397    &       -0.499     \\\\\n",
       "\\textbf{RAD}     &       0.2115  &        0.080     &     2.654  &         0.008        &        0.055    &        0.368     \\\\\n",
       "\\textbf{TAX}     &      -0.0119  &        0.005     &    -2.526  &         0.012        &       -0.021    &       -0.003     \\\\\n",
       "\\textbf{PTRATIO} &      -0.3033  &        0.135     &    -2.243  &         0.026        &       -0.569    &       -0.037     \\\\\n",
       "\\textbf{B}       &       0.0146  &        0.003     &     4.538  &         0.000        &        0.008    &        0.021     \\\\\n",
       "\\textbf{LSTAT}   &      -0.4181  &        0.060     &    -6.988  &         0.000        &       -0.536    &       -0.300     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 187.113 & \\textbf{  Durbin-Watson:     } &    1.930  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 1593.538  \\\\\n",
       "\\textbf{Skew:}          &   1.898 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  12.300 & \\textbf{  Cond. No.          } & 8.96e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [3] The condition number is large, 8.96e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                   MEDV   R-squared (uncentered):                   0.959\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.957\n",
       "Method:                 Least Squares   F-statistic:                              654.2\n",
       "Date:                Mon, 02 Sep 2024   Prob (F-statistic):                   3.71e-244\n",
       "Time:                        19:43:34   Log-Likelihood:                         -1141.9\n",
       "No. Observations:                 379   AIC:                                      2310.\n",
       "Df Residuals:                     366   BIC:                                      2361.\n",
       "Df Model:                          13                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "CRIM          -0.1312      0.041     -3.236      0.001      -0.211      -0.051\n",
       "ZN             0.0448      0.018      2.543      0.011       0.010       0.079\n",
       "INDUS          0.0077      0.078      0.098      0.922      -0.146       0.161\n",
       "CHAS           2.5157      1.045      2.407      0.017       0.460       4.571\n",
       "NOX           -3.3773      4.116     -0.821      0.412     -11.470       4.716\n",
       "RM             5.8394      0.374     15.619      0.000       5.104       6.575\n",
       "AGE           -0.0104      0.016     -0.661      0.509      -0.041       0.020\n",
       "DIS           -0.9479      0.228     -4.150      0.000      -1.397      -0.499\n",
       "RAD            0.2115      0.080      2.654      0.008       0.055       0.368\n",
       "TAX           -0.0119      0.005     -2.526      0.012      -0.021      -0.003\n",
       "PTRATIO       -0.3033      0.135     -2.243      0.026      -0.569      -0.037\n",
       "B              0.0146      0.003      4.538      0.000       0.008       0.021\n",
       "LSTAT         -0.4181      0.060     -6.988      0.000      -0.536      -0.300\n",
       "==============================================================================\n",
       "Omnibus:                      187.113   Durbin-Watson:                   1.930\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1593.538\n",
       "Skew:                           1.898   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.300   Cond. No.                     8.96e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 8.96e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(predictors, response, test_size= 0.25, random_state=314)\n",
    "\n",
    "model = OLS(ytrain, xtrain) #OLS asume que no hay intercepto\n",
    "ols = model.fit() #aquí se entrena o se 'ajusta' el modelo.\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo que lo anterior nos dice es que podemos modelar el 'valor de una casa' como:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MEDV = -0.1312*CRIM + 0.0448*ZN + 0.0077*INDUS + 2.5157*CHAS +...-0.4181*LSTAT$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.880958509702708"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ols = ols.predict(xtest)\n",
    "z = (y_ols - ytest)**2\n",
    "z.sum()/len(z) #error cuadrático medio (de predicción sobre conjunto de test/prueba) - mean squared error (mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125    22.168288\n",
       "262    41.725985\n",
       "40     34.681190\n",
       "35     22.747024\n",
       "375    26.901880\n",
       "         ...    \n",
       "203    41.375187\n",
       "418     2.847329\n",
       "466    12.730842\n",
       "268    37.597809\n",
       "43     24.361507\n",
       "Length: 127, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ols #estas son las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125    21.4\n",
       "262    48.8\n",
       "40     34.9\n",
       "35     18.9\n",
       "375    15.0\n",
       "       ... \n",
       "203    48.5\n",
       "418     8.8\n",
       "466    19.0\n",
       "268    43.5\n",
       "43     24.7\n",
       "Name: MEDV, Length: 127, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest #los valores reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ridge Regression [Hoerl and Kennard, 1970]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivación:\n",
    "1. Colinealidad --> aumenta varianza del estimador de mínimos cuadrados\n",
    "2. Esto puede afectar la predicción de nuestro modelo\n",
    "\n",
    "La colinealidad puede medirse mediante el indice de condición de una matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El índice de condición de una matrix $X$ puede expresarse como $ \\kappa(X)=\\sqrt{\\frac{\\lambda_1}{\\lambda_2}}$, donde $\\lambda_1$ y $\\lambda_2$ son los eigenvalores más grande y más pequeño, respectivamente, de $X^TX$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"eigeneigen.png\" alt=\"Alt text\" style=\"width: 1000px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " C2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación Regresión Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "La Regresión Ridge es una técnica de regresión lineal **regularizada** (CONTROLA EL TAMAÑO DE LOS COEFICIENTES) que ayuda a tratar con el problema de multicolinealidad (cuando las variables independientes están altamente correlacionadas) y a prevenir el sobreajuste. Esto lo logra al introducir un término de penalización al tamaño de los coeficientes en la función de costo.\n",
    "\n",
    "La función de costo en la regresión Ridge se modifica añadiendo un término de penalización basado en la suma de los cuadrados de los coeficientes:\n",
    "\n",
    "$$\n",
    "J(\\beta) = \\text{MSE}(\\beta) + \\lambda \\sum_{i=1}^{p} \\beta_i^2\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $J(\\beta)$ es la función de costo total.\n",
    "- $\\text{MSE}(\\beta)$ representa el error cuadrático medio, igual al de regresión lineal ordinaria.\n",
    "- $\\beta_i$ son los coeficientes del modelo para cada variable independiente (excluyendo el término de intercepción $\\beta_0$).\n",
    "- $\\lambda$ es el parámetro de regularización que controla cuánto queremos penalizar los grandes coeficientes. Una $\\lambda$ mayor incrementa la penalización sobre los coeficientes, lo que puede llevar a modelos más simples.\n",
    "\n",
    "El propósito del término de regularización $\\lambda \\sum_{i=1}^{p} \\beta_i^2$ es reducir la magnitud de los coeficientes, lo cual puede ayudar a **disminuir el riesgo de sobreajuste**. Los coeficientes más pequeños indican un modelo más simple y menos sensible a las fluctuaciones en los datos de entrenamiento, lo que puede mejorar la capacidad del modelo para generalizar bien a nuevos datos.\n",
    "\n",
    "La elección de $\\lambda$ es crucial: un valor muy alto puede hacer que el modelo sea demasiado simple y no capture bien la complejidad de los datos (subajuste o underfitting), mientras que un valor muy bajo puede llevar a poco efecto de la regularización, manteniendo el problema de sobreajuste (overfitting). La selección de una $\\lambda$ óptima generalmente se realiza mediante técnicas como la validación cruzada.\n",
    "\n",
    "En el modelo que estamos ajustando para predecir precios de casas basado en características como crimen per cápita, tamaño, número de habitaciones, etc, sin regularización, nuestro modelo podría ajustarse demasiado a los datos de entrenamiento, capturando ruido **en lugar de la relación subyacente**. Con la Regresión Ridge, se reduce el impacto de las características menos importantes (mediante la reducción de sus coeficientes), enfocándose en capturar la relación general en lugar de las peculiaridades de los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La formulación más conocida de Regresión Ridge es la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El estimador de Regresión Ridge se obtiene minimizando la siguiente función objetivo:\n",
    "\n",
    "$$\n",
    "\\text{argmin}_{\\beta} \\left\\{ \\sum_{i=1}^n (y_i - \\mathbf{x}_i^T \\beta)^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 \\right\\}\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{x}_i$ es un vector de $p \\times 1$ de predictores para la $i$-ésima observación, $y_i$ es la variable respuesta para la $i$-ésima observación y $\\lambda$ es el parámetro de regularización.\n",
    "\n",
    "En notación matricial, la función objetivo se puede escribir como:\n",
    "\n",
    "$$\n",
    "\\text{min}_{\\beta} (\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) + \\lambda \\beta^T \\beta \\qquad\\qquad\\qquad ... (1)\n",
    "$$\n",
    "\n",
    "que es equivalente a:\n",
    "$$\n",
    "\\text{min}_{\\beta} (\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) + \\lambda ||\\beta||^2 \\qquad\\qquad\\qquad ... (2)\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{X}$ es una matriz de $n \\times p$ de variables predictoras para todas las $n$ observaciones, $\\mathbf{y}$ es un vector de $n \\times 1$ con los valores de la variable respuesta para todas las $n$ observaciones, y $\\beta$ es un vector de $p \\times 1$ de coeficientes de regresión.\n",
    "\n",
    "Expandiendo la función objetivo, tenemos:\n",
    "\n",
    "$$\n",
    "(\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) + \\lambda \\beta^T \\beta = \\beta^T \\left(\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I} \\right) \\beta - 2 \\beta^T \\mathbf{X}^T \\mathbf{y} + \\mathbf{y}^T \\mathbf{y}\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{I}$ es la matriz identidad de $p \\times p$.\n",
    "\n",
    "Para minimizar la función objetivo, tomamos la derivada con respecto a $\\beta$ y la igualamos a cero:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\beta} \\left[ \\beta^T \\left(\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I} \\right) \\beta - 2 \\beta^T \\mathbf{X}^T \\mathbf{y} + \\mathbf{y}^T \\mathbf{y} \\right] = 2 \\left(\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I} \\right) \\beta - 2 \\mathbf{X}^T \\mathbf{y} = 0   \\qquad\\qquad\\qquad ... (3)\n",
    "$$\n",
    "\n",
    "Resolviendo para $\\hat{\\beta}_{ridge}$, obtenemos:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_{ridge} = \\left(\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I} \\right)^{-1} \\mathbf{X}^T \\mathbf{y}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión (2) es equivalente al problema de optimización:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{min}_{\\beta}(\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) \\newline\\newline\n",
    "s.t. \\|\\beta\\|^2 \\leq t\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: en la expresión (3), al sacar la derivada en múltiples dimensiones lo que estamos haciendo es **calcular el VECTOR GRADIENTE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación del parámetro $\\lambda$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la práctica, el valor de $\\lambda$ se obtiene mediante **validación cruzada (cross validation)**, cuya idea principal es dividir el *training* dataset de diferentes maneras para probar el modelo. \n",
    "\n",
    "El método k-fold cross-validation divide el *training* dataset en $k$ partes. Para cada una de las $k$ partes, entrenamos el modelo considerando $k-1$ partes y probamos el desempeño del modelo en la $k$-ésima parte:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"validacion_cruzada.png\" alt=\"Alt text\" style=\"width: 1200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando Ridge con RidgeCV() y Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeCV(alphas=array([0.01 , 0.015, 0.02 , 0.025, 0.03 , 0.035, 0.04 , 0.045, 0.05 ,\n",
       "       0.055, 0.06 , 0.065, 0.07 , 0.075, 0.08 , 0.085, 0.09 , 0.095,\n",
       "       0.1  , 0.105, 0.11 , 0.115, 0.12 , 0.125, 0.13 , 0.135, 0.14 ,\n",
       "       0.145, 0.15 , 0.155, 0.16 , 0.165, 0.17 , 0.175, 0.18 , 0.185,\n",
       "       0.19 , 0.195, 0.2  , 0.205, 0.21 , 0.215, 0.22 , 0.225, 0.23 ,\n",
       "       0.235, 0.24 , 0.245, 0.25 , 0.255, 0.26 , 0.265, 0.27 , 0.275,\n",
       "       0.28 , 0.285, 0.29 , 0.295, 0.3  , 0.305, 0...\n",
       "       2.755, 2.76 , 2.765, 2.77 , 2.775, 2.78 , 2.785, 2.79 , 2.795,\n",
       "       2.8  , 2.805, 2.81 , 2.815, 2.82 , 2.825, 2.83 , 2.835, 2.84 ,\n",
       "       2.845, 2.85 , 2.855, 2.86 , 2.865, 2.87 , 2.875, 2.88 , 2.885,\n",
       "       2.89 , 2.895, 2.9  , 2.905, 2.91 , 2.915, 2.92 , 2.925, 2.93 ,\n",
       "       2.935, 2.94 , 2.945, 2.95 , 2.955, 2.96 , 2.965, 2.97 , 2.975,\n",
       "       2.98 , 2.985, 2.99 , 2.995]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
       "        scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RidgeCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.RidgeCV.html\">?<span>Documentation for RidgeCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RidgeCV(alphas=array([0.01 , 0.015, 0.02 , 0.025, 0.03 , 0.035, 0.04 , 0.045, 0.05 ,\n",
       "       0.055, 0.06 , 0.065, 0.07 , 0.075, 0.08 , 0.085, 0.09 , 0.095,\n",
       "       0.1  , 0.105, 0.11 , 0.115, 0.12 , 0.125, 0.13 , 0.135, 0.14 ,\n",
       "       0.145, 0.15 , 0.155, 0.16 , 0.165, 0.17 , 0.175, 0.18 , 0.185,\n",
       "       0.19 , 0.195, 0.2  , 0.205, 0.21 , 0.215, 0.22 , 0.225, 0.23 ,\n",
       "       0.235, 0.24 , 0.245, 0.25 , 0.255, 0.26 , 0.265, 0.27 , 0.275,\n",
       "       0.28 , 0.285, 0.29 , 0.295, 0.3  , 0.305, 0...\n",
       "       2.755, 2.76 , 2.765, 2.77 , 2.775, 2.78 , 2.785, 2.79 , 2.795,\n",
       "       2.8  , 2.805, 2.81 , 2.815, 2.82 , 2.825, 2.83 , 2.835, 2.84 ,\n",
       "       2.845, 2.85 , 2.855, 2.86 , 2.865, 2.87 , 2.875, 2.88 , 2.885,\n",
       "       2.89 , 2.895, 2.9  , 2.905, 2.91 , 2.915, 2.92 , 2.925, 2.93 ,\n",
       "       2.935, 2.94 , 2.945, 2.95 , 2.955, 2.96 , 2.965, 2.97 , 2.975,\n",
       "       2.98 , 2.985, 2.99 , 2.995]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
       "        scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RidgeCV(alphas=array([0.01 , 0.015, 0.02 , 0.025, 0.03 , 0.035, 0.04 , 0.045, 0.05 ,\n",
       "       0.055, 0.06 , 0.065, 0.07 , 0.075, 0.08 , 0.085, 0.09 , 0.095,\n",
       "       0.1  , 0.105, 0.11 , 0.115, 0.12 , 0.125, 0.13 , 0.135, 0.14 ,\n",
       "       0.145, 0.15 , 0.155, 0.16 , 0.165, 0.17 , 0.175, 0.18 , 0.185,\n",
       "       0.19 , 0.195, 0.2  , 0.205, 0.21 , 0.215, 0.22 , 0.225, 0.23 ,\n",
       "       0.235, 0.24 , 0.245, 0.25 , 0.255, 0.26 , 0.265, 0.27 , 0.275,\n",
       "       0.28 , 0.285, 0.29 , 0.295, 0.3  , 0.305, 0...\n",
       "       2.755, 2.76 , 2.765, 2.77 , 2.775, 2.78 , 2.785, 2.79 , 2.795,\n",
       "       2.8  , 2.805, 2.81 , 2.815, 2.82 , 2.825, 2.83 , 2.835, 2.84 ,\n",
       "       2.845, 2.85 , 2.855, 2.86 , 2.865, 2.87 , 2.875, 2.88 , 2.885,\n",
       "       2.89 , 2.895, 2.9  , 2.905, 2.91 , 2.915, 2.92 , 2.925, 2.93 ,\n",
       "       2.935, 2.94 , 2.945, 2.95 , 2.955, 2.96 , 2.965, 2.97 , 2.975,\n",
       "       2.98 , 2.985, 2.99 , 2.995]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
       "        scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1) #Aquí estamos definiendo la forma de validación cruzada que queremos\n",
    "model = RidgeCV(alphas = np.arange(0.01, 3, 0.005), cv=cv, scoring= 'neg_mean_absolute_error') #definimos el modelo\n",
    "model.fit(xtrain, ytrain) #aquí es donde se lleva a cabo el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37499999999999994\n"
     ]
    }
   ],
   "source": [
    "print(model.alpha_) # la lambda (alpha) que minimiza el error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.38276688e-01,  4.21073672e-02,  1.14995884e-02,  2.28952993e+00,\n",
       "       -1.23471301e+01,  3.87374479e+00, -7.52187473e-03, -1.34117452e+00,\n",
       "        3.23991945e-01, -1.51038650e-02, -7.75008908e-01,  9.58497226e-03,\n",
       "       -5.22772814e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       -0.138277\n",
       "ZN          0.042107\n",
       "INDUS       0.011500\n",
       "CHAS        2.289530\n",
       "NOX       -12.347130\n",
       "RM          3.873745\n",
       "AGE        -0.007522\n",
       "DIS        -1.341175\n",
       "RAD         0.323992\n",
       "TAX        -0.015104\n",
       "PTRATIO    -0.775009\n",
       "B           0.009585\n",
       "LSTAT      -0.522773\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_series = pd.Series(model.coef_, model.feature_names_in_)\n",
    "coef_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.797763372453364"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ridge = model.predict(xtest)\n",
    "z = (y_ridge - ytest)**2\n",
    "z.sum()/len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.12419614147909963"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21.79/24.88 -1  #mejoramos el error de predicción en 12.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.375)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Ridge<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Ridge.html\">?<span>Documentation for Ridge</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Ridge(alpha=0.375)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=0.375)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Si ya sabemos nuestra lambda 'óptima' (alpha), podríamos entrenar un modelo con ese valor\n",
    "rreg = Ridge(alpha = 0.375)\n",
    "rreg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.797763372453364"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ridge = rreg.predict(xtest)\n",
    "z = (y_ridge - ytest)**2\n",
    "z.sum()/len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Respecto a la estimación del parámetro de regularización:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"regularization_lambda.png\" alt=\"Alt text\" style=\"width: 800px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas = np.arange(0.01, 3, 0.005)\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    model = RidgeCV(alphas=[a], cv=cv)\n",
    "    model.fit(predictors, response)\n",
    "    coefs.append(model.coef_)\n",
    "\n",
    "\n",
    "# Gráfico\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('linear')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Ridge coefficients')\n",
    "plt.xlim(-1, 10)\n",
    "plt.ylim(-15, 5)\n",
    "plt.title('Ridge coefficients as a function of lambda')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shrinkage techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Elements of Statistical Learning  friedman, hastie, tibshirani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepto: Gradiente de una función escalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El vector gradiente de una función escalar $f(x_1, x_2, \\ldots, x_n)$ de varias variables es un vector que contiene todas las derivadas parciales de esa función. **Indica la dirección en la cual la función aumenta más rápidamente**. La magnitud del gradiente te da la **tasa de incremento máximo en esa dirección**.\n",
    "\n",
    "Formalmente, el vector gradiente se define como:\n",
    "\n",
    "$$\n",
    "\\nabla f = \\left[ \\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right]^T\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $\\nabla f$ es el vector gradiente de la función $f$.\n",
    "- $\\frac{\\partial f}{\\partial x_i}$ representa la derivada parcial de $f$ con respecto a la variable $x_i$.\n",
    "- $T$ indica transposición, asegurando que el gradiente se presente como un **vector columna**.\n",
    "\n",
    "El vector gradiente apunta en la dirección del mayor aumento de la función y su magnitud indica cuán rápido aumenta la función en esa dirección. En el caso de una función de una **sola variable, el gradiente se reduce a la derivada de la función**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"quadraticprog.png\" alt=\"Alt text\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En el punto mínimo el gradiente es cero:\n",
    "\n",
    "<img src=\"quadratic_min_grad.png\" alt=\"Alt text\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visto desde arriba:\n",
    "<img src=\"quadratic_projected.png\" alt=\"Alt text\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Descenso de Gradiente (Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Inicializar** los parámetros $\\beta$ y elegir una tasa de aprendizaje $\\eta$ (learning rate).\n",
    "2. **Repetir hasta convergencia:** Esto significa iterar hasta que el cambio en la función objetivo entre iteraciones sucesivas sea pequeño (menor que un umbral predefinido) o hasta alcanzar un número máximo de iteraciones.\n",
    "   - Calcular el gradiente de la función objetivo $J(\\beta)$ respecto a los parámetros, $\\nabla_{\\beta} J(\\beta)$.\n",
    "   - Actualizar los parámetros: $\\beta_{t+1} = \\beta_{t} - \\eta \\nabla_{\\beta} J(\\beta_{t})$.\n",
    "3. **Detener** el proceso cuando se cumpla el criterio de salida (por ejemplo, convergencia alcanzada o número máximo de iteraciones).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: implementación sencilla de Gradient Descent PARA MÍNIMO CUADRADOS ORDINARIOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergencia alcanzada en la iteración 226.\n",
      "Theta encontrados por descenso de gradiente:\n",
      "[[4.21199475]\n",
      " [2.97747952]]\n"
     ]
    }
   ],
   "source": [
    "# Generamos datos sintéticos\n",
    "np.random.seed(0)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)   # y = 4 + 3*x + error\n",
    "\n",
    "# Agregar término constante a X\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "\n",
    "# Parámetros del algoritmo de descenso de gradiente\n",
    "learning_rate = 0.05\n",
    "n_iterations = 1000\n",
    "m = len(X_b)\n",
    "tolerance = 1e-6 # Tolerancia para el cambio en la función de costo\n",
    "\n",
    "theta = np.random.randn(2,1) # Inicialización aleatoria\n",
    "\n",
    "cost_history = [np.inf] # Iniciar historial de costo con infinito\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y) #ESTE ES EL VECTOR GRADIENTE\n",
    "    theta = theta - learning_rate * gradients  #ACTUALIZADNO EL PARÁMETRO\n",
    "    cost = (1/m) * np.sum((X_b.dot(theta) - y)**2) # Calcular el nuevo costo\n",
    "    if abs(cost_history[-1] - cost) < tolerance: # validar la condición de salida o \"stop\"\n",
    "        print(f\"Convergencia alcanzada en la iteración {iteration}.\")\n",
    "        break\n",
    "    cost_history.append(cost)\n",
    "\n",
    "print(\"Theta encontrados por descenso de gradiente:\")\n",
    "print(theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- fin clase 28 Agosto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- inicio clase 29 Agosto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión LASSO (least absolute shrinkage and selection operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión LASSO es otra técnica de regresión lineal regularizada, muy similar a la regresión Ridge, pero con una diferencia clave en el tipo de penalización que aplica a los coeficientes. La regresión LASSO no sólo ayuda a tratar con multicolinealidad y a prevenir el sobreajuste, sino que también puede realizar selección de variables al forzar algunos coeficientes a ser **exactamente cero**. Esto significa que LASSO puede excluir automáticamente variables menos importantes del modelo, lo que es útil para la simplificación del modelo y la interpretación de los resultados.\n",
    "\n",
    "La función de costo en la regresión LASSO se define como:\n",
    "\n",
    "$$\n",
    "J(\\beta) = \\text{MSE}(\\beta) + \\lambda \\sum_{i=1}^{p} |\\beta_i|\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $J(\\beta)$ es la función de costo total.\n",
    "- $\\text{MSE}(\\beta)$ es el error cuadrático medio.\n",
    "- $\\beta_i$ son los coeficientes del modelo para cada variable independiente (excluyendo el término de intercepción $\\beta_0$).\n",
    "- $\\lambda$ es el parámetro de regularización. Al igual que en  Ridge, controla la intensidad de la penalización, pero aquí se aplica a la suma de los valores absolutos de los coeficientes.\n",
    "\n",
    "La principal diferencia entre LASSO y Ridge es en el tipo de penalización: LASSO utiliza la suma de los valores absolutos de los coeficientes ($\\ell_1$ penalización), mientras que Ridge utiliza la suma de los cuadrados ($\\ell_2$ penalización). Esta diferencia hace que LASSO pueda reducir algunos coeficientes exactamente a cero, lo cual es una forma de realizar selección de variables dentro del proceso de modelado.\n",
    "\n",
    "Ventajas de LASSO:\n",
    "- **Selección de Variables:** LASSO puede identificar y descartar variables no informativas automáticamente.\n",
    "- **Interpretabilidad:** Al reducir el número de variables, el modelo se hace más sencillo y fácil de interpretar.\n",
    "- **Prevención del Sobreajuste:** Al igual que Ridge, ayuda a prevenir el sobreajuste limitando la magnitud de los coeficientes.\n",
    "\n",
    "La selección del parámetro $\\lambda$ es crucial en LASSO, donde un balance adecuado puede significar la diferencia entre un modelo bien ajustado y uno que no capta la complejidad o que ignora información importante. La validación cruzada suele ser el método preferido para encontrar un valor óptimo de $\\lambda$.\n",
    "\n",
    "Considera un conjunto de datos con muchas variables que intentan predecir el rendimiento académico de estudiantes. Algunas de estas variables pueden no tener un impacto significativo en el rendimiento. La regresión LASSO puede ser particularmente útil en este escenario, ya que automáticamente seleccionará las variables más relevantes $^{[nota]}$ (por ejemplo, horas de estudio, asistencia) y descartará las menos importantes, lo que resulta en un modelo más simple y enfocado.\n",
    "\n",
    "La regresión LASSO es una herramienta adecuada en aquellos casos donde la simplicidad y la interpretabilidad del modelo son tan importantes como la precisión de las predicciones.\n",
    "\n",
    "$nota$: cuidado con esta aseveración. Si bien LASSO sí puede hacer selección de variables, el orden en el que entre una variable al modelo puede ser la diferencia entre seleccionarla o no, así que tomar esto con cuidado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulación del Problema LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{min}_{\\beta} (\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) + \\lambda \\sum_{i=1}^{p} |\\beta_i| \\qquad\\qquad\\qquad ... (4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La expresión (4) es equivalente al problema de optimización:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{min}_{\\beta}(\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) \\newline\\newline\n",
    "s.t. \\sum_{i=1}^{p} |\\beta_i| \\leq t\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comentar:\n",
    "# Si sólo tuviéramos un número 'pequeño' de variables predictoras, cuál es el mejor ajuste que podemos obtener en te´rminos de suma de\n",
    "#cuadrados del error. \n",
    "\n",
    "# Una t suficientemente pequeña hace que los coefs se 'encojan' hacia el cero e incluso que algunos sean exactamente cero.\n",
    "\n",
    "# A diferencia de OLS y Ridge, no existe una solución cerrada para LASSO (excepto cuando X es ortonormal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curvas de nivel SSE y región factible  [Tibshirani, 1996]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"geom_lasso_ridge.png\" alt=\"Alt text\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo que se utiliza para la optimización de LASSO se llama **descenso por coordenada (coordinate descent)**:\n",
    "\n",
    "1. Para $j=0,1,\\dots,p$\n",
    "2. Calcula $\\rho_j = \\sum_{i=1}^n x_{ij}(y_{i}-\\sum_{k \\neq j}^p \\beta_k x^{(i)}_k)$\n",
    "3. Calcula $z_j = \\sum_{i=1}^n (x_{ij})^2$\n",
    "4. Actualiza $\\beta_j = \\frac{1}{z_j}S(\\rho_j,\\lambda)$\n",
    "\n",
    "5. Repetir pasos 2-4 hasta convergencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde $S(x,\\lambda)  = \\text{sign}(x) \\cdot \\max(|x| - \\lambda, 0)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A $S()$ se le conoce como el operador \"Soft Thresholding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El soft thresholding es una operación importante en la solución de LASSO  y otros problemas de optimización, especialmente cuando se utilizan métodos de descenso de coordenadas. Es una forma de fomentar 'sparcity' en los parámetros del modelo, realizando una selección de variables al establecer algunos coeficientes en cero.\n",
    "\n",
    "### ¿Qué es el soft thresholding?\n",
    "\n",
    "El soft thresholding es una operación aplicada a cada coeficiente durante el paso de actualización en el algoritmo de optimización. Se define por la siguiente función:\n",
    "\n",
    "$$\n",
    "S_{\\lambda}(x) = \\text{sign}(x) \\cdot \\max(|x| - \\lambda, 0)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $S_{\\lambda}(x)$ es el valor de $x$ después del soft thresholding,\n",
    "- $\\lambda$ es el parámetro de umbral (relacionado con el parámetro de regularización $\\alpha$ en LASSO),\n",
    "- $x$ es el valor original del coeficiente,\n",
    "- $\\text{sign}(x)$ devuelve el signo de $x$ (ya sea -1, 0 o 1).\n",
    "\n",
    "### ¿Cómo Funciona?\n",
    "\n",
    "1. **Reducción de Magnitud:** El soft thresholding reduce la magnitud de cada coeficiente por el umbral $\\lambda$, pero nunca por debajo de cero. Esta operación puede reducir a cero los coeficientes pequeños.\n",
    "\n",
    "2. **Preservación del Signo:** La operación preserva el signo del coeficiente original. Si $x$ es positivo, $S_{\\lambda}(x)$ también será positivo (o cero si $x$ es menor que $\\lambda$). De manera similar, si $x$ es negativo, el valor después del umbralizado será negativo o cero.\n",
    "\n",
    "3. **Fomenta 'sparcity':** Al establecer coeficientes pequeños en cero, el soft thresholding ayuda a identificar las variables más relevantes en un modelo. En conjuntos de datos de alta dimensión, donde el número de variables puede ser muy grande, esta propiedad es  valiosa.\n",
    "\n",
    "### Ejemplos:\n",
    "\n",
    "Si $x$ = 5 y $\\lambda$ = 3:\n",
    "$$\n",
    "S_{3}(5)= sign(5) \\cdot \\max(5 - 3, 0) = 1\\times 2 = 2 \n",
    "$$\n",
    "\n",
    "En nuestro ejemplo de regresión LASSO para predecir precios de casas basado en varias características, si tenemos un coeficiente $\\beta = 0.02$ con un umbral $\\lambda = 0.05$. El soft thresholding ajustaría este coeficiente a cero porque su magnitud es menor que el umbral, indicando que esta característica  podría no ser relevante para el modelo.\n",
    "\n",
    "En contraste, para un coeficiente $\\beta = 0.1$ con el mismo umbral, el soft thresholding reduciría su magnitud pero lo mantendría no nulo ($S_{0.05}(0.1) = 0.05$), preservando su influencia en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"soft_th.png\" alt=\"Alt text\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0  A1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1  A2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2  A3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3  A4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4  A5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('boston_house_prices.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando LASSO con LassoCV de Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos parámetros importantes de LassoCV:\n",
    "\n",
    "1. cv: el número de 'folds' de validación cruzada que se utilizan para evaluar el rendimiento del modelo. Por defecto es None, lo que significa que se utiliza una estrategia k=5. Si se establece en un entero k, se utiliza la estrategia de validación cruzada K-fold, con k folds.\n",
    "\n",
    "2. alphas: una lista o arreglo de valores de $\\alpha$ (lambdas) para probar. Si se establece como None, se utilizará una secuencia predeterminada de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valor óptimo de lambda:  0.007\n",
      "CRIM:-1.044\n",
      "ZN: 0.649\n",
      "INDUS: 0.277\n",
      "CHAS: 0.738\n",
      "NOX:-1.887\n",
      "RM: 3.145\n",
      "AGE:-0.240\n",
      "DIS:-2.907\n",
      "RAD: 2.091\n",
      "TAX:-1.532\n",
      "PTRATIO:-2.073\n",
      "B: 1.143\n",
      "LSTAT:-3.696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Cargar los datos y asignar predictoras (X) y respuesta (y):\n",
    "predictors = df.loc[:, 'CRIM':'LSTAT']\n",
    "response = df['MEDV']\n",
    "\n",
    "#PARTICIONANDO los datos en conjunto de entrenamiento y prueba (testing).\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, response, test_size = 0.25, random_state=42)\n",
    "\n",
    "# Escalar los datos usando StandardScaler\n",
    "scaler = StandardScaler()  # Z= (X - promedio)/ desv_std\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Crear un modelo de regresión LASSO con validación cruzada para determinar el parámetro de regularización lambda (alphas)\n",
    "lasso_cv = LassoCV(cv=5, random_state=42)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# imprimir el valor óptimo de lambda (parámetro de regularización):\n",
    "print(f\"valor óptimo de lambda: {lasso_cv.alpha_: .3f}\")\n",
    "\n",
    "#imprimir los coeficientes del modelo:\n",
    "coeficientes = dict(zip(predictors.columns, lasso_cv.coef_))\n",
    "for variable, coef in coeficientes.items():\n",
    "    print(f\"{variable}:{coef: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notemos que ninguno de los coeficientes fue cero en este caso. ¿Por qué?\n",
    "# Porque tenemos predictoras que en vdad están asociadas con la variable respuesta\n",
    "# También, no tenemos muchas variables predictoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.11064649660294"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict y mse\n",
    "y_lasso = lasso_cv.predict(X_test_scaled)\n",
    "z = (y_lasso - y_test)**2\n",
    "z.sum()/len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1113344051446945"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22.11/24.88-1 # mEJORAMOS el error de predicción en 11.13% wrt a OLS\n",
    "#Recordar que el error de Ridge fue de 21.79 (12.4% menos que OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Coordinate Descent para LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_thresholding(x, gamma): #ver figura Soft threshold vs OLS arriba\n",
    "    if x > 0 and gamma < abs(x):\n",
    "        return x-gamma\n",
    "    elif x < 0 and gamma < abs(x):\n",
    "        return x+gamma\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Coordinate descent para lasso\n",
    "\n",
    "def coordinate_descent_lasso(X, y, alpha, max_iter=100, tol=0.001):\n",
    "    \"\"\"Coordinate descent para Lasso\"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros(n_features)\n",
    "    w_old = np.zeros(n_features)  # inicializamos w_old\n",
    "    for i in range(max_iter):\n",
    "        for j in range(n_features):\n",
    "            X_j = X[:, j]\n",
    "            y_pred = X @ w\n",
    "            r = y - y_pred + w[j] * X_j\n",
    "            w[j] = soft_thresholding(np.dot(X_j, r) / n_samples, alpha / n_samples)\n",
    "        if np.max(np.abs(w - w_old)) < tol:\n",
    "            break\n",
    "        w_old = w.copy()  # actualizamos w_old\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.06423852,  0.67998084,  0.33787068,  0.73772321, -1.93188992,\n",
       "        3.14307464, -0.25710817, -2.95542152,  2.20676774, -1.64467811,\n",
       "       -2.08677573,  1.15217142, -3.69376277])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_lasso = coordinate_descent_lasso(X_train_scaled, y_train, alpha=0.007, max_iter=1000)\n",
    "c_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -1.064239\n",
       "ZN         0.679981\n",
       "INDUS      0.337871\n",
       "CHAS       0.737723\n",
       "NOX       -1.931890\n",
       "RM         3.143075\n",
       "AGE       -0.257108\n",
       "DIS       -2.955422\n",
       "RAD        2.206768\n",
       "TAX       -1.644678\n",
       "PTRATIO   -2.086776\n",
       "B          1.152171\n",
       "LSTAT     -3.693763\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_lasso = pd.Series(c_lasso, predictors.columns)\n",
    "coefs_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net: Una combinación de Ridge y Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión Elastic Net es una técnica que combina las fortalezas de dos métodos de regularización: LASSO ($\\ell_1$) y Ridge ($\\ell_2$). Esto  permite que Elastic Net herede las ventajas de ambos, siendo particularmente útil en situaciones donde hay muchas variables correlacionadas entre sí o cuando el número de predictores supera el número de observaciones. Elastic Net **puede** reducir la variabilidad en las estimaciones de los coeficientes y realizar una selección de variables más efectiva que LASSO o Ridge por sí solos.\n",
    "\n",
    "La función de costo de la regresión Elastic Net se define como:\n",
    "\n",
    "$$\n",
    "J(\\beta) = \\text{MSE}(\\beta) + r \\alpha \\sum_{i=1}^{p} |\\beta_i| + \\frac{1-r}{2} \\alpha \\sum_{i=1}^{p} \\beta_i^2\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $J(\\beta)$ es la función de costo total.\n",
    "- $\\text{MSE}(\\beta)$ es el error cuadrático medio, el mismo de mínimos cuadrados.\n",
    "- $\\beta_i$ son los coeficientes del modelo para cada variable independiente (excluyendo el término de intercepción $\\beta_0$).\n",
    "- $\\alpha$ es el parámetro de regularización que controla la intensidad total de la penalización.\n",
    "- $r$, conocido como $\\ell_1$- ratio, es el parámetro que equilibra la proporción de las penalizaciones $\\ell_1$ y $\\ell_2$, con valores que van de 0 a 1.\n",
    "\n",
    "Ventajas de Elastic Net:\n",
    "\n",
    "- **Manejo de Colinealidad** \n",
    "- **Selección de Variables:** Puede reducir algunos coeficientes a cero, lo que significa que realiza selección de variables, eliminando predictores no informativos del modelo.\n",
    "- **Estabilidad:** En escenarios donde el número de predictores es mayor que el número de observaciones, o cuando hay un grupo de variables altamente correlacionadas, Elastic Net tiende a ser más estable que LASSO o Ridge por separado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de optimización es:\n",
    "$$\n",
    "\\text{min}_{\\beta}\\frac{1}{2n} (\\mathbf{y} - \\mathbf{X} \\beta)^T (\\mathbf{y} - \\mathbf{X} \\beta) + r \\alpha \\sum_{i=1}^{p} |\\beta_i| + \\frac{1-r}{2} \\alpha \\sum_{i=1}^{p} \\beta_i^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $\\ell_1$- ratio = 1 --> Elastic Net se reduce a Lasso\n",
    "2. $\\ell_1$- ratio = 0 --> Elastic Net se reduce a Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#motivación:\n",
    "# 1. Si p > n, Lasso selecciona a LO MÁS n variables. \n",
    "# 2. Si hay grupos de variables correlacionadas, LASSO selecciona UNA de esas variables, sin importar. \n",
    "# 3. para n > p , si hay mucha colinealidad, Ridge tiende a desempeñar mejor que LASSO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nota:\n",
    "El valor óptimo de $r$ y $\\alpha$ depende del grado de colinealidad de los datos, del proceso generador de los coeficientes 'verdaderos', del número de predictoras y de la relación entre predictoras y variable respuesta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Región factible de los coeficientes de Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"en_region.png\" alt=\"Alt text\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha óptimo: 0.031269227497471096\n",
      "L1_ratio óptimo: 0.2239999999999998\n"
     ]
    }
   ],
   "source": [
    "# Implementar modelo\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "#aSIGNAR X, y:\n",
    "predictors = df.loc[:, 'CRIM':'LSTAT']\n",
    "response = df['MEDV']\n",
    "\n",
    "#PARTICIONANDO los datos en conjunto de entrenamiento y prueba (testing).\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, response, test_size = 0.25, random_state=42)\n",
    "\n",
    "#estandarizar los datos:\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#crear el modelo de Elastic Net con validación cruzada con DIFERENTES l1_ratio:\n",
    "\n",
    "elastic_net_cv = ElasticNetCV(l1_ratio = np.arange(0.01, 1, 0.001),\n",
    "                             n_alphas = 100, cv = 5, max_iter=10000)\n",
    "elastic_net_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Imprimir valores óptimos de alpha (parámetro de regularización) y de l_1 ratio\n",
    "print(f\"Alpha óptimo: {elastic_net_cv.alpha_}\")\n",
    "print(f\"L1_ratio óptimo: {elastic_net_cv.l1_ratio_}\") #r óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM      -0.961947\n",
       "ZN         0.529972\n",
       "INDUS      0.101739\n",
       "CHAS       0.764264\n",
       "NOX       -1.629700\n",
       "RM         3.174487\n",
       "AGE       -0.244340\n",
       "DIS       -2.609664\n",
       "RAD        1.565742\n",
       "TAX       -1.096079\n",
       "PTRATIO   -1.981436\n",
       "B          1.117020\n",
       "LSTAT     -3.592074\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_en = pd.Series(elastic_net_cv.coef_, predictors.columns)\n",
    "coefs_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.285836866693465"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_en = elastic_net_cv.predict(X_test_scaled)\n",
    "z = (y_en - y_test)**2\n",
    "z.sum()/len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10450160771704176"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22.28/24.88-1  #mejoramos 10.45% vs OLS\n",
    "#OLS < EN < LASSO < RIDGE en ESTE CONJUNTO DE DATOS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
